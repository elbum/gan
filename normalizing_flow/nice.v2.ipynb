{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NICE with MNIST\n",
    "\n",
    "* `NICE: Non-Linear Independent Components Estimation`, [arXiv:1410.8516](https://arxiv.org/abs/1410.8516)\n",
    "  * Laurent Dinh, David Krueger and Yoshua Bengio\n",
    "  \n",
    "* Implemented by [`tf.keras.layers`](https://www.tensorflow.org/api_docs/python/tf/keras/layers) and [`eager execution`](https://www.tensorflow.org/guide/eager)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "from utils.image_utils import *\n",
    "from utils.ops import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'nice'\n",
    "train_dir = os.path.join('train', model_name, 'exp1')\n",
    "\n",
    "max_epochs = 1500\n",
    "save_model_epochs = 100\n",
    "print_steps = 50\n",
    "save_images_epochs = 50\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "num_examples_to_generate = 16\n",
    "MNIST_SIZE = 28\n",
    "noise_dim = MNIST_SIZE**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data.reshape(-1, MNIST_SIZE**2).astype('float32')\n",
    "train_data = train_data / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`\n",
    "\n",
    "### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_uniform_noise(image):\n",
    "  noise = tf.random.uniform(image.get_shape(), maxval=1./255)\n",
    "  return tf.clip_by_value(image + noise, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (256, 784), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(219)\n",
    "\n",
    "# for train\n",
    "N = len(train_data)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "train_dataset = train_dataset.map(_add_uniform_noise)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NICE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUMLP(tf.keras.Model):\n",
    "  def __init__(self, input_size):\n",
    "    super(ReLUMLP, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.fc1 = layers.Dense(units=1000, activation='relu')\n",
    "    self.fc2 = layers.Dense(units=1000, activation='relu')\n",
    "    self.fc3 = layers.Dense(units=1000, activation='relu')\n",
    "    #self.fc4 = layers.Dense(units=1000, activation='relu')\n",
    "    #self.fc5 = layers.Dense(units=1000, activation='relu')\n",
    "    self.fc4 = layers.Dense(units=MNIST_SIZE**2-self.input_size)\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    fc1 = self.fc1(inputs)\n",
    "    fc2 = self.fc2(fc1)\n",
    "    fc3 = self.fc3(fc2)\n",
    "    fc4 = self.fc4(fc3)\n",
    "    #fc5 = self.fc5(fc4)\n",
    "    #fc6 = self.fc6(fc5)\n",
    "    \n",
    "    return fc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(inputs, method='oddeven', p1_size=MNIST_SIZE**2//2):\n",
    "  if method == 'oddeven':\n",
    "    partition1 = inputs[:, 0::2]\n",
    "    partition2 = inputs[:, 1::2]\n",
    "  elif method == 'topdown':\n",
    "    partition1 = inputs[:, :p1_size]\n",
    "    partition2 = inputs[:, p1_size:]\n",
    "  else:\n",
    "    raise ValueError('Not allowed method')\n",
    "    \n",
    "  return partition1, partition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(partition1, partition2, method='oddeven'):\n",
    "  if method == 'oddeven':\n",
    "    merged = []\n",
    "    for j in range(partition1.shape[1]):\n",
    "      merged.append(partition1[:,j])\n",
    "      merged.append(partition2[:,j])\n",
    "    merged = tf.stack(merged, axis=1)\n",
    "  elif method == 'topdown':\n",
    "    merged = tf.concat((partition1, partition2), axis=1)\n",
    "  else:\n",
    "    raise ValueError('Not allowed method')\n",
    "\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveCouplingLayer(tf.keras.Model):\n",
    "  def __init__(self, partition_method, input_size):\n",
    "    super(AdditiveCouplingLayer, self).__init__()\n",
    "    self.partition_method = partition_method\n",
    "    self.input_size = input_size\n",
    "    self.relumlp = ReLUMLP(self.input_size)\n",
    "    \n",
    "    # (random) permutation index\n",
    "    indices = np.asarray(range(MNIST_SIZE**2), dtype=np.int32)\n",
    "    indices = np.random.permutation(indices)\n",
    "    \n",
    "    # Reverse it\n",
    "    indices_inverse = np.zeros(shape=indices.shape, dtype=np.int32)\n",
    "    for i in range(MNIST_SIZE**2):\n",
    "      indices_inverse[indices[i]] = i\n",
    "    \n",
    "    # convert to tensor\n",
    "    self.tf_indices = tf.Variable(indices, trainable=None, name='tf_indices', dtype=tf.int32)\n",
    "    self.tf_indices_inverse = tf.Variable(indices_inverse, trainable=None, name='tf_indices_inverse', dtype=tf.int32)\n",
    "    \n",
    "  def call(self, x):\n",
    "    # permutation x\n",
    "    x = tf.gather(x, self.tf_indices, axis=1)\n",
    "    x1, x2 = partition(x, self.partition_method)\n",
    "    y1 = x1\n",
    "    y2 = x2 + self.relumlp(x1)\n",
    "    \n",
    "    return merge(y1, y2, self.partition_method)\n",
    "    \n",
    "  def inverse(self, y):\n",
    "    y1, y2 = partition(y, self.partition_method)\n",
    "    x1 = y1\n",
    "    x2 = y2 - self.relumlp(y1)\n",
    "    x = merge(x1, x2, self.partition_method)\n",
    "    # inverse permutation x\n",
    "    x = tf.gather(x, self.tf_indices_inverse, axis=1)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NICE(tf.keras.Model):\n",
    "  def __init__(self, partition_method, partition_size):\n",
    "    super(NICE, self).__init__()\n",
    "    self.partition_method = partition_method\n",
    "    self.partition_size1 = partition_size\n",
    "    self.partition_size2 = MNIST_SIZE**2 - partition_size\n",
    "    \n",
    "    self.coupling1 = AdditiveCouplingLayer(self.partition_method, self.partition_size1)\n",
    "    self.coupling2 = AdditiveCouplingLayer(self.partition_method, self.partition_size2)\n",
    "    self.coupling3 = AdditiveCouplingLayer(self.partition_method, self.partition_size1)\n",
    "    self.coupling4 = AdditiveCouplingLayer(self.partition_method, self.partition_size2)\n",
    "    self.log_scaling = tf.Variable(np.zeros([MNIST_SIZE**2]), trainable=True, name='log_scaling', dtype=tf.float32)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    h1 = self.coupling1(inputs)\n",
    "    h2 = self.coupling2(h1)\n",
    "    h3 = self.coupling3(h2)\n",
    "    h4 = self.coupling4(h3)\n",
    "    h = h4 * tf.exp(self.log_scaling)\n",
    "    \n",
    "    return h, self.log_scaling\n",
    "  \n",
    "  def generate_sample(self, noise_vector):\n",
    "    h4 = noise_vector / tf.exp(self.log_scaling)\n",
    "    h3 = self.coupling4.inverse(h4)\n",
    "    h2 = self.coupling3.inverse(h3)\n",
    "    h1 = self.coupling2.inverse(h2)\n",
    "    x = self.coupling1.inverse(h1)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice = NICE(partition_method='oddeven', partition_size=MNIST_SIZE**2//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss functions and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(h, prior='gaussian'):\n",
    "  if prior == 'logistic':\n",
    "    log_likelihood = -tf.reduce_sum( tf.math.softplus(h) + tf.math.softplus(-h), axis=1 )\n",
    "  elif prior == 'gaussian':\n",
    "    log_likelihood = -0.5 * tf.reduce_sum(h**2, axis=1)\n",
    "\n",
    "  return -tf.reduce_mean(log_likelihood, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.01, epsilon=1e-4)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = train_dir\n",
    "if not tf.io.gfile.exists(checkpoint_dir):\n",
    "  tf.io.gfile.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, nice=nice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement of the nice.\n",
    "location = 0.0 # location\n",
    "scale = 0.5 # scale\n",
    "random_vector_for_generation = tf.random.normal([num_examples_to_generate, noise_dim], mean=location, stddev=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training one step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "  with tf.GradientTape() as tape:\n",
    "    hidden_state, log_scaling = nice(images)\n",
    "    nll = negative_log_likelihood(hidden_state, prior='logistic')\n",
    "    ss = -tf.reduce_sum(log_scaling) # sum of log scaling\n",
    "    loss = nll + ss\n",
    "\n",
    "  gradients = tape.gradient(loss, nice.variables)\n",
    "  optimizer.apply_gradients(zip(gradients, nice.trainable_variables))\n",
    "\n",
    "  return loss, nll, ss, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 34.40 global_step: 8050 loss: -1922.184  negative log likelihood: 1633.249  ss: -3555.434  max_ss: 7.07  min_ss: 0.916  max_h: 17.9  min_h: -7.4  (4279.87 examples/sec; 0.060 sec/batch)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Start Training.')\n",
    "num_batches_per_epoch = int(N / batch_size)\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  for step, images in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    loss, nll, ss, hidden_state = train_step(images)\n",
    "    global_step.assign_add(1)\n",
    "    \n",
    "    if global_step.numpy() % print_steps == 0:\n",
    "      epochs = epoch + step / float(num_batches_per_epoch)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      display.clear_output(wait=True)\n",
    "      print(\"Epochs: {:.2f} global_step: {} loss: {:.3f}  negative log likelihood: {:.3f}  ss: {:.3f}  max_ss: {:.3g}  min_ss: {:.3g}  max_h: {:.3g}  min_h: {:.3g}  ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n",
    "                epochs, global_step.numpy(), loss, nll, ss,\n",
    "                nice.log_scaling[tf.argmax(nice.log_scaling)],\n",
    "                nice.log_scaling[tf.argmin(nice.log_scaling)],\n",
    "                hidden_state[0][tf.argmax(hidden_state[0])],\n",
    "                hidden_state[1][tf.argmin(hidden_state[1])],\n",
    "                examples_per_sec, duration))\n",
    "      sample_images = nice.generate_sample(random_vector_for_generation)\n",
    "      print_or_save_sample_images(sample_images.numpy(), num_examples_to_generate)\n",
    "\n",
    "  if (epoch + 1) % save_images_epochs == 0:\n",
    "    display.clear_output(wait=True)\n",
    "    print(\"This images are saved at {} epoch\".format(epoch+1))\n",
    "    sample_images = nice.generate_sample(random_vector_for_generation)\n",
    "    print_or_save_sample_images(sample_images.numpy(), num_examples_to_generate,\n",
    "                                is_square=True, is_save=True, epoch=epoch+1,\n",
    "                                checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "  # saving (checkpoint) the model every save_epochs\n",
    "  if (epoch + 1) % save_model_epochs == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating after the final epoch\n",
    "display.clear_output(wait=True)\n",
    "sample_images = nice.generate_sample(random_vector_for_generation)\n",
    "print_or_save_sample_images(sample_images.numpy(), num_examples_to_generate,\n",
    "                            is_square=True, is_save=True, epoch=epoch+1,\n",
    "                            checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f0526bb50d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display an image using the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train/nice/exp1/image_at_epoch_1500.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-47360e2452da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ai/projects/generative.models.tensorflow.v2/utils/image_utils.py\u001b[0m in \u001b[0;36mdisplay_image\u001b[0;34m(epoch_no, name, checkpoint_dir)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'image_at_epoch_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{:04d}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/nice/exp1/image_at_epoch_1500.png'"
     ]
    }
   ],
   "source": [
    "display_image(max_epochs, checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a GIF of all the saved images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-938cd2bc0cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.gif'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerate_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_name' is not defined"
     ]
    }
   ],
   "source": [
    "filename = model_name + '_' + dataset_name + '.gif'\n",
    "generate_gif(filename, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3d9c531cb29c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "display.Image(filename=filename + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
