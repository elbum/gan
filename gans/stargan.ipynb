{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StarGAN [with celebA dataset]\n",
    "\n",
    "* `Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks`, [arXiv:1703.10593](https://arxiv.org/abs/1703.10593)\n",
    "  * Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros\n",
    "  \n",
    "* This code is available to tensorflow version 2.0\n",
    "* Implemented by [`tf.keras.layers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers) [`tf.losses`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:25.962441Z",
     "start_time": "2019-03-10T03:17:23.026084Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "from utils.image_utils import *\n",
    "from utils.ops import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:25.972765Z",
     "start_time": "2019-03-10T03:17:25.965740Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:25.980842Z",
     "start_time": "2019-03-10T03:17:25.975968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'stargan'\n",
    "train_dir = os.path.join('train', model_name, 'exp1')\n",
    "dataset_name = 'celebA'\n",
    "assert dataset_name in ['celebA']\n",
    "\n",
    "constant_lr_epochs = 10\n",
    "decay_lr_epochs = 10\n",
    "max_epochs = constant_lr_epochs + decay_lr_epochs\n",
    "save_model_epochs = 2\n",
    "print_steps = 10\n",
    "save_images_epochs = 1\n",
    "batch_size = 16\n",
    "learning_rate_D = 1e-4\n",
    "learning_rate_G = 1e-4\n",
    "k = 1 # the number of step of learning D before learning G\n",
    "num_examples_to_generate = 1\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "IMG_SIZE = 128\n",
    "num_domain = 5\n",
    "LAMBDA_class = 1\n",
    "LAMBDA_reconstruction = 10\n",
    "gp_lambda = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "You can download celebA dataset from [here](https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/). \n",
    "\n",
    "As mentioned in the [paper](https://arxiv.org/abs/1703.10593) we apply random jittering and mirroring to the training dataset.\n",
    "* In random jittering, the image is resized to 286 x 286 and then randomly cropped to 256 x 256\n",
    "* In random mirroring, the image is randomly flipped horizontally i.e left to right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actually create random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:25.998030Z",
     "start_time": "2019-03-10T03:17:25.987489Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 2000\n",
    "train_images = np.random.uniform(low=-1., high=1., size=[N, IMG_SIZE, IMG_SIZE, 3]).astype(np.float32)\n",
    "train_labels = np.random.uniform(low=0, high=num_domain, size=[N]).astype(np.int32)\n",
    "\n",
    "test_images = np.random.uniform(low=-1., high=1., size=[N, IMG_SIZE, IMG_SIZE, 3]).astype(np.float32)\n",
    "test_labels = np.random.uniform(low=0, high=num_domain, size=[N]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tf.data to create batches, map(do preprocessing) and shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "  one_hot_label = tf.one_hot(label, depth=num_domain)\n",
    "  return image, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.139132Z",
     "start_time": "2019-03-10T03:17:26.025346Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.map(preprocessing)\n",
    "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.139132Z",
     "start_time": "2019-03-10T03:17:26.025346Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.map(preprocessing)\n",
    "test_dataset = test_dataset.batch(num_examples_to_generate, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the generator and discriminator models\n",
    "\n",
    "### Generator\n",
    "\n",
    "* The architecture of generator is similiar to [Johnson's architecture](https://arxiv.org/abs/1603.08155).\n",
    "* Conv block in the generator is (Conv -> InstanceNorm -> ReLU)\n",
    "* Res block in the generator is (Conv -> IN -> ReLU -> Conv -> IN -> add X -> ReLU)\n",
    "* ConvTranspose block in the generator is (Transposed Conv -> IN -> ReLU) (except last layer: tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(layers.Layer):\n",
    "  \"\"\"InstanceNormalization for only 4-rank Tensor (image data)\n",
    "  \"\"\"\n",
    "  def __init__(self, epsilon=1e-5):\n",
    "    super(InstanceNormalization, self).__init__()\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape)\n",
    "    param_shape = shape[-1]\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.gamma = self.add_weight(name='gamma',\n",
    "                                 shape=param_shape,\n",
    "                                 initializer='ones',\n",
    "                                 trainable=True)\n",
    "    self.beta = self.add_weight(name='beta',\n",
    "                                shape=param_shape,\n",
    "                                initializer='zeros',\n",
    "                                trainable=True)\n",
    "    # Make sure to call the `build` method at the end\n",
    "    super(InstanceNormalization, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Compute the axes along which to reduce the mean / variance\n",
    "    input_shape = inputs.get_shape()\n",
    "    reduction_axes = [1, 2] # only shape index\n",
    "    mean, variance = tf.nn.moments(inputs, reduction_axes, keepdims=True)\n",
    "    normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
    "    return self.gamma * normalized + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.311154Z",
     "start_time": "2019-03-10T03:17:26.299181Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv(tf.keras.Model):\n",
    "  def __init__(self, filters, size, strides=1, padding='same',\n",
    "               activation='relu', apply_norm='instance'):\n",
    "    super(Conv, self).__init__()\n",
    "    assert apply_norm in ['instance', 'none']\n",
    "    self.apply_norm = apply_norm\n",
    "    assert activation in ['relu', 'tanh', 'leaky_relu', 'none']\n",
    "    self.activation = activation\n",
    "    \n",
    "    if self.apply_norm == 'none':\n",
    "      use_bias = True\n",
    "    else:\n",
    "      use_bias = False\n",
    "    \n",
    "    self.conv = layers.Conv2D(filters=filters,\n",
    "                              kernel_size=(size, size),\n",
    "                              strides=strides,\n",
    "                              padding=padding,\n",
    "                              kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                              use_bias=use_bias)\n",
    "    \n",
    "    if self.apply_norm == 'instance':\n",
    "      self.instancenorm = InstanceNormalization()\n",
    "  \n",
    "  def call(self, x):\n",
    "    # convolution\n",
    "    x = self.conv(x)\n",
    "    \n",
    "    # normalization\n",
    "    if self.apply_norm == 'instance':\n",
    "      x = self.instancenorm(x)\n",
    "    \n",
    "    # activation\n",
    "    if self.activation == 'relu':\n",
    "      x = tf.nn.relu(x)\n",
    "    elif self.activation == 'tanh':\n",
    "      x = tf.nn.tanh(x)\n",
    "    elif self.activation == 'leaky_relu':\n",
    "      x = tf.nn.leaky_relu(x, alpha=0.01)\n",
    "    else:\n",
    "      pass\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.322805Z",
     "start_time": "2019-03-10T03:17:26.314298Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(tf.keras.Model):\n",
    "  def __init__(self, filters, size):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.conv1 = Conv(filters, size, activation='relu')\n",
    "    self.conv2 = Conv(filters, size, activation='none')\n",
    "  \n",
    "  def call(self, x):\n",
    "    conv = self.conv1(x)\n",
    "    conv = self.conv2(conv)\n",
    "    x = tf.nn.relu(x + conv)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.342360Z",
     "start_time": "2019-03-10T03:17:26.325917Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvTranspose(tf.keras.Model):\n",
    "  def __init__(self, filters, size, apply_norm='instance'):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    assert apply_norm in ['instance', 'none']\n",
    "    self.apply_norm = apply_norm\n",
    "    self.up_conv = layers.Conv2DTranspose(filters=filters,\n",
    "                                          kernel_size=(size, size),\n",
    "                                          strides=2,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                                          use_bias=False)\n",
    "    \n",
    "    if self.apply_norm == 'instance':\n",
    "      self.instancenorm = InstanceNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.up_conv(x)\n",
    "    if self.apply_norm == 'instance':\n",
    "      x = self.instancenorm(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.360464Z",
     "start_time": "2019-03-10T03:17:26.345520Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    self.down1 = Conv(64, 7)\n",
    "    self.down2 = Conv(128, 4, 2)\n",
    "    self.down3 = Conv(256, 4, 2)\n",
    "    \n",
    "    self.res1 = ResBlock(256, 3)\n",
    "    self.res2 = ResBlock(256, 3)\n",
    "    self.res3 = ResBlock(256, 3)\n",
    "    self.res4 = ResBlock(256, 3)\n",
    "    self.res5 = ResBlock(256, 3)\n",
    "    self.res6 = ResBlock(256, 3)\n",
    "    \n",
    "    self.up1 = ConvTranspose(128, 4)\n",
    "    self.up2 = ConvTranspose(64, 3)\n",
    "    self.last = Conv(3, 7, activation='tanh')\n",
    "\n",
    "  def call(self, images, labels):\n",
    "    # images shape: (bs, 128, 128, 3)\n",
    "    # labels shape: (bs, num_domain) -> (bs, 128, 128, num_domain)\n",
    "    # x shape: (bs, 128, 128, 3 + num_domain)\n",
    "    labels = tf.expand_dims(tf.expand_dims(labels, axis=1), axis=2)\n",
    "    x = tf.concat([images,\n",
    "                   labels * tf.ones([images.shape[0],\n",
    "                                     IMG_SIZE, IMG_SIZE, num_domain])], axis=3)\n",
    "    x1 = self.down1(x)     # x1 shape: (bs, 128, 128, 32)\n",
    "    x2 = self.down2(x1)    # x2 shape: (bs, 64, 64, 64)\n",
    "    x3 = self.down3(x2)    # x3 shape: (bs, 32, 32, 128)\n",
    "    \n",
    "    x4 = self.res1(x3)     # x4 shape: (bs, 32, 32, 128)\n",
    "    x5 = self.res2(x4)     # x5 shape: (bs, 32, 32, 128)\n",
    "    x6 = self.res3(x5)     # x6 shape: (bs, 32, 32, 128)\n",
    "    x7 = self.res4(x6)     # x7 shape: (bs, 32, 32, 128)\n",
    "    x8 = self.res5(x7)     # x8 shape: (bs, 32, 32, 128)\n",
    "    x9 = self.res6(x8)     # x8 shape: (bs, 32, 32, 128)\n",
    "\n",
    "    x10 = self.up1(x9)     # x10 shape: (bs, 64, 64, 64)\n",
    "    x11 = self.up2(x10)    # x11 shape: (bs, 128, 128, 32)\n",
    "    generated_images = self.last(x11) # generated_images shape: (bs, 128, 128, 3)\n",
    "\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test a generators\n",
    "generator = Generator()\n",
    "\n",
    "#gen_output = generator(images[tf.newaxis, ...], training=False)\n",
    "gen_output = generator(images, labels)\n",
    "plt.imshow(gen_output[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "* The Discriminator is a variation of PatchGAN.\n",
    "* Each block in the discriminator is (Conv -> Leaky ReLU), **NO** normalization\n",
    "* The shape of the output after the last layer is (batch_size, 2, 2, 1)\n",
    "\n",
    "To learn more about the architecture and the hyperparameters you can refer the [paper](https://arxiv.org/abs/1711.09020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.394331Z",
     "start_time": "2019-03-10T03:17:26.380196Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()    \n",
    "    self.down1 = Conv(64, 4, 2, activation='leaky_relu', apply_norm='none')\n",
    "    self.down2 = Conv(128, 4, 2, activation='leaky_relu', apply_norm='none')\n",
    "    self.down3 = Conv(256, 4, 2, activation='leaky_relu', apply_norm='none')\n",
    "    self.down4 = Conv(512, 4, 2, activation='leaky_relu', apply_norm='none')\n",
    "    self.down5 = Conv(1024, 4, 2, activation='leaky_relu', apply_norm='none')\n",
    "    self.down6 = Conv(2048, 4, 2, activation='leaky_relu', apply_norm='none')\n",
    "    \n",
    "    self.source = Conv(1, 3, activation='none', apply_norm='none')\n",
    "    self.classification = Conv(5, 2, padding='valid', activation='none', apply_norm='none')\n",
    "  \n",
    "  @tf.function\n",
    "  def call(self, x):\n",
    "    # x shape == (bs, 128, 128, 3)\n",
    "    x = self.down1(x) # (bs, 64, 64, 64)\n",
    "    x = self.down2(x) # (bs, 32, 32, 128)\n",
    "    x = self.down3(x) # (bs, 16, 16, 256)\n",
    "    x = self.down4(x) # (bs, 8, 8, 512)\n",
    "    x = self.down5(x) # (bs, 4, 4, 1024)\n",
    "    x = self.down6(x) # (bs, 2, 2, 2048)\n",
    "    \n",
    "    disc_logits = self.source(x)                   # (bs, 2, 2, 1)\n",
    "    classification_logits = self.classification(x) # (bs, 1, 1, 5)\n",
    "    classification_logits = tf.squeeze(classification_logits, axis=[1, 2])\n",
    "\n",
    "    return disc_logits, classification_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.471031Z",
     "start_time": "2019-03-10T03:17:26.400019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and test a discriminator\n",
    "discriminator = Discriminator()\n",
    "\n",
    "#disc_out = discriminator(images[tf.newaxis,...], training=False)\n",
    "disc_out1, disc_out2 = discriminator(images)\n",
    "print(disc_out2[0])\n",
    "plt.imshow(disc_out1[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss functions and the optimizer\n",
    "\n",
    "* **Discriminator loss**\n",
    "  * The discriminator loss function takes 2 inputs; real images, generated images\n",
    "  * real_loss is a sigmoid cross entropy loss of the real images and an array of ones(since these are the real images)\n",
    "  * generated_loss is a sigmoid cross entropy loss of the generated images and an array of zeros(since these are the fake images)\n",
    "  * Then the total_loss is the sum of real_loss and the generated_loss\n",
    "* **Generator loss**\n",
    "  * It is a sigmoid cross entropy loss of the generated images and an array of ones.\n",
    "  * The paper also includes L1 loss which is MAE (mean absolute error) between the generated image and the target image.\n",
    "  * This allows the generated image to become structurally similar to the target image.\n",
    "  * The formula to calculate the total generator loss = gan_loss + LAMBDA * l1_loss, where LAMBDA = 100. This value was decided by the authors of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_object = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "mse_object = tf.losses.MeanSquaredError()\n",
    "mae_object = tf.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.503635Z",
     "start_time": "2019-03-10T03:17:26.488583Z"
    }
   },
   "outputs": [],
   "source": [
    "def GANLoss(logits, is_real=True, use_lsgan=True):\n",
    "  \"\"\"Computes standard GAN or LSGAN loss between `logits` and `labels`.\n",
    "\n",
    "  Args:\n",
    "    logits (`2-rank Tensor`): logits.\n",
    "    is_real (`bool`): True means `1` labeling, False means `0` labeling.\n",
    "    use_lsgan (`bool`): True means LSGAN loss, False means standard GAN loss.\n",
    "\n",
    "  Returns:\n",
    "    loss (`0-rank Tensor`): the standard GAN or LSGAN loss value. (binary_cross_entropy or mean_squared_error)\n",
    "  \"\"\"\n",
    "  if is_real:\n",
    "    labels = tf.ones_like(logits)\n",
    "  else:\n",
    "    labels = tf.zeros_like(logits)\n",
    "    \n",
    "  if use_lsgan:\n",
    "    loss = mse_object(y_true=labels, y_pred=tf.nn.sigmoid(logits))\n",
    "  else:\n",
    "    loss = bce_object(y_true=labels, y_pred=logits)\n",
    "    \n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGANLoss(logits, is_real=True):\n",
    "  \"\"\"Computes Wasserstain GAN loss\n",
    "\n",
    "  Args:\n",
    "    logits (`2-rank Tensor`): logits\n",
    "    is_real (`bool`): boolean, Treu means `-` sign, False means `+` sign.\n",
    "\n",
    "  Returns:\n",
    "    loss (`0-rank Tensor`): the WGAN loss value.\n",
    "  \"\"\"\n",
    "  loss = tf.reduce_mean(logits)\n",
    "  if is_real:\n",
    "    loss = -loss\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.525520Z",
     "start_time": "2019-03-10T03:17:26.519670Z"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits, real_class_logits, original_labels):\n",
    "  # losses of real with label \"1\"\n",
    "  real_loss = WGANLoss(logits=real_logits, is_real=True)\n",
    "  # losses of fake with label \"0\"\n",
    "  fake_loss = WGANLoss(logits=fake_logits, is_real=False)\n",
    "  \n",
    "  # domain classification loss\n",
    "  domain_class_loss = bce_object(real_class_logits, original_labels)\n",
    "  \n",
    "  return real_loss + fake_loss + (LAMBDA_class * domain_class_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.536977Z",
     "start_time": "2019-03-10T03:17:26.529930Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle_consistency_loss(X, X2Y2X):\n",
    "  cycle_loss = mae_object(y_true=X, y_pred=X2Y2X) # L1 loss\n",
    "  #cycle_loss = mse_object(y_true=X, y_pred=X2Y2X) # L2 loss\n",
    "  \n",
    "  return cycle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.625649Z",
     "start_time": "2019-03-10T03:17:26.590116Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_logits, fake_class_logits, target_domain, input_images, generated_images_o2t2o):\n",
    "  # losses of Generator with label \"1\" that used to fool the Discriminator\n",
    "  gan_loss = WGANLoss(logits=fake_logits, is_real=True)\n",
    "  \n",
    "  # domain classification loss\n",
    "  domain_class_loss = bce_object(fake_class_logits, target_domain)\n",
    "  \n",
    "  # mean absolute error\n",
    "  cycle_loss = cycle_consistency_loss(input_images, generated_images_o2t2o)\n",
    "\n",
    "  return gan_loss + (LAMBDA_class * domain_class_loss) + (LAMBDA_reconstruction * cycle_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define learning rate decay functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.646371Z",
     "start_time": "2019-03-10T03:17:26.631712Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_D = learning_rate_D\n",
    "def get_lr_D(global_step):\n",
    "  global lr_D\n",
    "  num_steps_per_epoch = int(N / batch_size)\n",
    "  if global_step.numpy() > num_steps_per_epoch * constant_lr_epochs:\n",
    "    decay_step = num_steps_per_epoch * decay_lr_epochs\n",
    "    lr_D = lr_D - (learning_rate_D * 1. / decay_step) # tf.train.polynomial_decay (linear decay)\n",
    "    return lr_D\n",
    "  else:\n",
    "    return lr_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.701169Z",
     "start_time": "2019-03-10T03:17:26.691395Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_G = learning_rate_G\n",
    "def get_lr_G(global_step):\n",
    "  global lr_G\n",
    "  num_steps_per_epoch = int(N / batch_size)\n",
    "  if global_step.numpy() > num_steps_per_epoch * constant_lr_epochs:\n",
    "    decay_step = num_steps_per_epoch * decay_lr_epochs\n",
    "    lr_G = lr_G - (learning_rate_G * 1. / decay_step) # tf.train.polynomial_decay (linear decay)\n",
    "    return lr_G\n",
    "  else:\n",
    "    return lr_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.716423Z",
     "start_time": "2019-03-10T03:17:26.707166Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.Adam(get_lr_D(global_step), beta_1=0.5)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(get_lr_G(global_step), beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.733394Z",
     "start_time": "2019-03-10T03:17:26.722132Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = train_dir\n",
    "if not tf.io.gfile.exists(checkpoint_dir):\n",
    "  tf.io.gfile.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generate_and_print_or_save functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.772958Z",
     "start_time": "2019-03-10T03:17:26.763608Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_print_or_save(inputs, lables, target_domain=None,\n",
    "                               is_save=False, epoch=None, checkpoint_dir=checkpoint_dir):\n",
    "  n = inputs.shape[0]\n",
    "  if target_domain is None:\n",
    "    target_domain = tf.random.uniform(shape=[n], minval=0, maxval=num_domain, dtype=tf.int32)\n",
    "    target_domain = tf.one_hot(target_domain, depth=num_domain)\n",
    "    \n",
    "  assert n == target_domain.shape[0]\n",
    "  generated_images_o2t = generator(inputs, target_domain)\n",
    "  generated_images_o2t2o = generator(generated_images_o2t, lables)\n",
    "\n",
    "  print_or_save_sample_images_pix2pix(const_test_inputs, generated_images_o2t, generated_images_o2t2o,\n",
    "                                      model_name='stargan', name=None,\n",
    "                                      is_save=is_save, epoch=epoch, checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:26.852862Z",
     "start_time": "2019-03-10T03:17:26.779111Z"
    }
   },
   "outputs": [],
   "source": [
    "# keeping the constant test input for generation (prediction) so\n",
    "# it will be easier to see the improvement of the pix2pix.\n",
    "for inputs, labels in test_dataset.take(1):\n",
    "  const_test_inputs = inputs\n",
    "  const_test_labels = labels\n",
    "  \n",
    "const_target_domains = tf.random.uniform(shape=[const_test_inputs.shape[0]], minval=0, maxval=num_domain, dtype=tf.int32)\n",
    "const_target_domains = tf.one_hot(const_target_domains, depth=num_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:17:30.508009Z",
     "start_time": "2019-03-10T03:17:26.856540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for test data X -> Y -> X\n",
    "generate_and_print_or_save(const_test_inputs, const_test_labels, const_target_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:24:48.241117Z",
     "start_time": "2019-03-10T03:24:48.238689Z"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training one step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def discriminator_train_step(input_images, labels):\n",
    "  # generating target domain\n",
    "  target_domain = tf.random.uniform(shape=[batch_size], minval=0, maxval=num_domain, dtype=tf.int32)\n",
    "  target_domain = tf.one_hot(target_domain, depth=num_domain)\n",
    "  \n",
    "  with tf.GradientTape() as disc_tape:\n",
    "    # Image generation from original domain to target domain\n",
    "    generated_images_o2t = generator(input_images, target_domain)\n",
    "    # Image generation from target domain to original domain\n",
    "    generated_images_o2t2o = generator(generated_images_o2t, labels)\n",
    "\n",
    "    real_logits, real_class_logits = discriminator(input_images)\n",
    "    fake_logits, fake_class_logits = discriminator(generated_images_o2t)\n",
    "    \n",
    "    \n",
    "    # interpolation of x hat for gradient penalty : epsilon * real image + (1 - epsilon) * generated image\n",
    "    epsilon = tf.random.uniform([batch_size])\n",
    "    epsilon = tf.expand_dims(tf.stack([tf.stack([epsilon]*IMG_SIZE, axis=1)]*IMG_SIZE, axis=1), axis=3)\n",
    "    interpolated_images_4gp = epsilon * images + (1. - epsilon) * generated_images_o2t\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "      gp_tape.watch(interpolated_images_4gp)\n",
    "      interpolated_images_logits, _ = discriminator(interpolated_images_4gp)\n",
    "      \n",
    "    gradients_of_interpolated_images = gp_tape.gradient(interpolated_images_logits, interpolated_images_4gp)\n",
    "    norm_grads = tf.sqrt(tf.reduce_sum(tf.square(gradients_of_interpolated_images), axis=[1, 2, 3]))\n",
    "    gradient_penalty_loss = tf.reduce_mean(tf.square(norm_grads - 1.))\n",
    "    \n",
    "    disc_loss = discriminator_loss(real_logits, fake_logits, real_class_logits, labels) + \\\n",
    "                    gp_lambda * gradient_penalty_loss\n",
    "    gen_loss = generator_loss(fake_logits, fake_class_logits, target_domain, input_images, generated_images_o2t2o)\n",
    "    \n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "  \n",
    "  return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def generator_train_step(input_images, labels):\n",
    "  # generating target domain\n",
    "  target_domain = tf.random.uniform(shape=[batch_size], minval=0, maxval=num_domain, dtype=tf.int32)\n",
    "  target_domain = tf.one_hot(target_domain, depth=num_domain)\n",
    "  \n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    # Image generation from original domain to target domain\n",
    "    generated_images_o2t = generator(input_images, target_domain)\n",
    "    # Image generation from target domain to original domain\n",
    "    generated_images_o2t2o = generator(generated_images_o2t, labels)\n",
    "\n",
    "    real_logits, real_class_logits = discriminator(input_images)\n",
    "    fake_logits, fake_class_logits = discriminator(generated_images_o2t)\n",
    "\n",
    "    gen_loss = generator_loss(fake_logits, fake_class_logits, target_domain, input_images, generated_images_o2t2o)\n",
    "\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training until max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:18:33.119012Z",
     "start_time": "2019-03-10T03:17:30.705494Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Start Training.')\n",
    "num_batches_per_epoch = int(N / batch_size)\n",
    "num_learning_critic = 0\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "  for step, (images, labels) in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if num_learning_critic < k:\n",
    "      gen_loss, disc_loss = discriminator_train_step(images, labels)\n",
    "      num_learning_critic += 1\n",
    "      global_step.assign_add(1)\n",
    "    else:\n",
    "      generator_train_step(images, labels)\n",
    "      num_learning_critic = 0\n",
    "\n",
    "    # print the result images every print_steps\n",
    "    if global_step.numpy() % print_steps == 0:\n",
    "      epochs = epoch + step / float(num_batches_per_epoch)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      display.clear_output(wait=True)\n",
    "      print(\"Epochs: {:.2f} lr: {:.3g}, {:.3g}, global_step: {} loss_D: {:.3g} loss_G: {:.3g} ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n",
    "                epochs, generator_optimizer.lr.numpy(), discriminator_optimizer.lr.numpy(), global_step.numpy(), disc_loss, gen_loss, examples_per_sec, duration))\n",
    "      # generate image to target domain for test_dataset\n",
    "      for test_inputs, test_labels in test_dataset.take(1):\n",
    "        generate_and_print_or_save(test_inputs, test_labels)\n",
    "\n",
    "  # saving the result image files every save_images_epochs\n",
    "  if (epoch + 1) % save_images_epochs == 0:\n",
    "    display.clear_output(wait=True)\n",
    "    print(\"This images are saved at {} epoch\".format(epoch+1))\n",
    "    generate_and_print_or_save(const_test_inputs, const_test_labels, const_target_domains,\n",
    "                               is_save=True, epoch=epoch+1, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "  # saving (checkpoint) the model every save_epochs\n",
    "  if (epoch + 1) % save_model_epochs == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "print('Training Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:18:34.536883Z",
     "start_time": "2019-03-10T03:18:33.121400Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating after the final epoch\n",
    "display.clear_output(wait=True)\n",
    "generate_and_print_or_save(const_test_inputs, const_test_labels, const_target_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:18:35.376184Z",
     "start_time": "2019-03-10T03:18:34.540701Z"
    }
   },
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display an image using the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:18:35.861571Z",
     "start_time": "2019-03-10T03:18:35.396028Z"
    }
   },
   "outputs": [],
   "source": [
    "display_image(max_epochs, checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a GIF of all the saved images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:18:36.064979Z",
     "start_time": "2019-03-10T03:17:23.560Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = model_name + '_' + dataset_name + '.gif'\n",
    "generate_gif(filename, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T03:18:36.068567Z",
     "start_time": "2019-03-10T03:17:23.563Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display.Image(filename=filename + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
